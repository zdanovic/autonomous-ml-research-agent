#!/usr/bin/env python
"""
Comet-Swarm CLI Runner - –£–ø—Ä–∞–≤–ª—è–µ–º—ã–π –∑–∞–ø—É—Å–∫ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è—Ö.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    uv run python examples/run_competition.py --platform wundernn --mode debug
    uv run python examples/run_competition.py --platform kaggle --mode full
"""

import argparse
import asyncio
from pathlib import Path

import polars as pl

from comet_swarm.agents import StrategistAgent
from comet_swarm.integrations import ExperimentTracker, get_tracer
from comet_swarm.platforms import KaggleAdapter, SolafuneAdapter, WundernnAdapter
from comet_swarm.tools import (
    correlation_analysis,
    cross_validate,
    lag_features,
    profile_dataset,
    rolling_stats,
)

# =============================================================================
# Configuration
# =============================================================================

PLATFORMS = {
    "wundernn": {
        "adapter": WundernnAdapter,
        "data_format": "parquet",
        "target_cols": ["t0", "t1"],
        "description": "LOB Predictorium (Pearson correlation)",
    },
    "solafune": {
        "adapter": SolafuneAdapter,
        "data_format": "csv",
        "target_cols": ["construction_cost_per_m2_usd"],
        "description": "Construction Cost (RMSLE)",
    },
    "kaggle": {
        "adapter": KaggleAdapter,
        "data_format": "csv",
        "target_cols": ["water_level"],
        "description": "Urban Flood Modelling (R¬≤)",
    },
}

MODES = {
    "debug": {
        "max_iterations": 1,
        "n_folds": 2,
        "sample_size": 1000,
        "description": "–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (1 –∏—Ç–µ—Ä–∞—Ü–∏—è, 2 —Ñ–æ–ª–¥–∞, 1K —Å—ç–º–ø–ª–æ–≤)",
    },
    "test": {
        "max_iterations": 3,
        "n_folds": 3,
        "sample_size": 10000,
        "description": "–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ (3 –∏—Ç–µ—Ä–∞—Ü–∏–∏, 3 —Ñ–æ–ª–¥–∞, 10K —Å—ç–º–ø–ª–æ–≤)",
    },
    "full": {
        "max_iterations": 10,
        "n_folds": 5,
        "sample_size": None,  # Use all data
        "description": "–ü–æ–ª–Ω—ã–π –∑–∞–ø—É—Å–∫ (10 –∏—Ç–µ—Ä–∞—Ü–∏–π, 5-fold CV)",
    },
}


def print_header(text: str):
    """–ü–µ—á–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∞."""
    print("\n" + "=" * 60)
    print(f"  {text}")
    print("=" * 60)


def print_step(step: int, text: str):
    """–ü–µ—á–∞—Ç—å —à–∞–≥–∞."""
    print(f"\n[{step}] {text}")


async def run_competition(
    platform: str,
    mode: str,
    data_path: str | None = None,
    skip_download: bool = False,
    dry_run: bool = False,
):
    """
    –ó–∞–ø—É—Å–∫ –∞–≥–µ–Ω—Ç–∞ –Ω–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–∏.
    
    Args:
        platform: –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ (wundernn, solafune, kaggle)
        mode: –†–µ–∂–∏–º (debug, test, full)
        data_path: –ü—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º (–µ—Å–ª–∏ –Ω–µ —Å–∫–∞—á–∏–≤–∞—Ç—å)
        skip_download: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö
        dry_run: –¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å –ø–ª–∞–Ω –±–µ–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    """
    config = PLATFORMS[platform]
    mode_config = MODES[mode]
    
    print_header(f"üöÄ Comet-Swarm: {config['description']}")
    print(f"\nüìä –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞: {platform}")
    print(f"üîß –†–µ–∂–∏–º: {mode} - {mode_config['description']}")
    
    if dry_run:
        print("\n‚ö†Ô∏è  DRY RUN - —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–ª–∞–Ω, –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ–º")
        print("\n–ü–ª–∞–Ω –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:")
        print("  1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–µ–π—Å–µ—Ä–∞ –∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞")
        print("  2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –Ω–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ)")
        print("  3. EDA: –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ, –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏")
        print("  4. –°—Ç—Ä–∞—Ç–µ–≥–∏—è: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–∏–ø–æ—Ç–µ–∑ LLM")
        print("  5. –§–∏—á–∏: lag, rolling stats")
        print("  6. –û–±—É—á–µ–Ω–∏–µ: LightGBM CV")
        print("  7. –û—Ü–µ–Ω–∫–∞: –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        print("  8. (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –°–∞–±–º–∏—Ç")
        return
    
    # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    print_step(1, "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...")
    tracer = get_tracer()
    tracer.start_trace(f"{platform}_run")
    
    tracker = ExperimentTracker(
        project_name="comet-swarm",
        competition_name=f"{platform}_competition",
    )
    
    adapter = config["adapter"]()
    context = adapter.get_competition_context()
    
    print(f"  ‚úì –ú–µ—Ç—Ä–∏–∫–∞: {context.metric.value} ({context.metric_direction})")
    print(f"  ‚úì –§–æ—Ä–º–∞—Ç —Å–∞–±–º–∏—Ç–∞: {context.submission_format}")
    
    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print_step(2, "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    data_dir = Path(f"./data/{platform}")
    
    if data_path:
        train_path = Path(data_path)
        print(f"  –ò—Å–ø–æ–ª—å–∑—É–µ–º: {train_path}")
    elif skip_download:
        # –ò—â–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
        train_path = data_dir / f"train.{config['data_format']}"
        if not train_path.exists():
            print(f"  ‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {train_path}")
            print("  –£–∫–∞–∂–∏—Ç–µ --data-path –∏–ª–∏ —É–±–µ—Ä–∏—Ç–µ --skip-download")
            return
        print(f"  –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {train_path}")
    else:
        # –°–∫–∞—á–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        print("  –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã...")
        try:
            data_dir.mkdir(parents=True, exist_ok=True)
            paths = await adapter.download_data(data_dir)
            train_path = paths.get("train") or paths.get("train_dataset")
            if not train_path:
                print("  ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ")
                return
            print(f"  ‚úì –°–∫–∞—á–∞–Ω–æ: {train_path}")
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            print("  –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–∫–∞—á–∞—Ç—å –≤—Ä—É—á–Ω—É—é –∏ —É–∫–∞–∑–∞—Ç—å --data-path")
            return
    
    # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ
    print_step(3, "–ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
    
    if config["data_format"] == "parquet":
        df = pl.read_parquet(train_path)
    else:
        df = pl.read_csv(train_path)
    
    original_size = len(df)
    
    if mode_config["sample_size"] and len(df) > mode_config["sample_size"]:
        df = df.sample(n=mode_config["sample_size"], seed=42)
        print(f"  –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ: {original_size:,} ‚Üí {len(df):,} —Å—Ç—Ä–æ–∫")
    else:
        print(f"  –†–∞–∑–º–µ—Ä: {len(df):,} —Å—Ç—Ä–æ–∫")
    
    # 4. EDA
    print_step(4, "Exploratory Data Analysis...")
    
    target_col = config["target_cols"][0]
    
    # Check if target column exists, fallback to 'target' if not
    if target_col not in df.columns:
        if "target" in df.columns:
            target_col = "target"
            print(f"  ‚ö†Ô∏è Using fallback target column: {target_col}")
        else:
            print(f"  ‚ùå Target column '{target_col}' not found in data")
            print(f"     Available columns: {df.columns[:10]}...")
            return
    
    correlations = {}  # Initialize before try block
    
    try:
        dataset_info = profile_dataset(df, name=platform, target_column=target_col)
        print(f"  ‚úì –ö–æ–ª–æ–Ω–æ–∫: {dataset_info.num_columns}")
        print(f"  ‚úì –ü–∞–º—è—Ç—å: {dataset_info.memory_mb:.2f} MB")
        
        correlations = correlation_analysis(df, target_column=target_col, top_n=5)
        print(f"  ‚úì –¢–æ–ø –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ —Å {target_col}:")
        for feat, corr in list(correlations.items())[:3]:
            print(f"      {feat}: {corr:.4f}")
    except Exception as e:
        print(f"  ‚ö†Ô∏è EDA –æ—à–∏–±–∫–∞: {e}")
        dataset_info = None
    
    # 5. –°—Ç—Ä–∞—Ç–µ–≥–∏—è
    print_step(5, "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (LLM)...")
    
    strategist = StrategistAgent()
    
    dataset_summary = f"{len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫"
    eda_summary = "–¢–æ–ø –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏: " + ", ".join(
        [f"{k}={v:.3f}" for k, v in list(correlations.items())[:3]]
    ) if correlations else "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"
    
    try:
        strategy = await strategist.generate_strategy(
            competition_context=context.model_dump(),
            dataset_info=dataset_summary,
            eda_insights=eda_summary,
        )
        print(f"  ‚úì –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {strategy.priority[:80]}...")
        print(f"  ‚úì –ì–∏–ø–æ—Ç–µ–∑—ã: {len(strategy.hypotheses)}")
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏: {e}")
        return
    
    # 6. Feature Engineering
    print_step(6, "Feature Engineering...")
    
    numeric_cols = [c for c in df.columns if df[c].dtype.is_numeric() and c not in config["target_cols"]]
    
    if numeric_cols:
        try:
            # –ù–∞–π—Ç–∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–æ—á–Ω—É—é –∫–æ–ª–æ–Ω–∫—É (–µ—Å–ª–∏ –µ—Å—Ç—å)
            group_col = None
            for candidate in ["seq_ix", "id", "building_id", "node_id"]:
                if candidate in df.columns:
                    group_col = candidate
                    break
            
            # Lag features
            feature_col = numeric_cols[0]
            if group_col:
                df = lag_features(df, column=feature_col, lags=[1, 3], group_by=group_col)
                df = rolling_stats(df, column=feature_col, windows=[3], stats=["mean"], group_by=group_col)
            else:
                df = lag_features(df, column=feature_col, lags=[1, 3])
                df = rolling_stats(df, column=feature_col, windows=[3], stats=["mean"])
            
            new_features = [c for c in df.columns if "lag" in c or "roll" in c]
            print(f"  ‚úì –ù–æ–≤—ã—Ö —Ñ–∏—á: {len(new_features)}")
        except Exception as e:
            print(f"  ‚ö†Ô∏è Feature engineering –æ—à–∏–±–∫–∞: {e}")
    else:
        print("  ‚ö†Ô∏è –ù–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è —Ñ–∏—á–µ–π")
    
    # 7. Training
    print_step(7, f"Model Training ({mode_config['n_folds']}-fold CV)...")
    
    # Exclude target_col from features (avoid duplicate in select)
    feature_cols = [c for c in df.columns if c not in config["target_cols"] and c != target_col and df[c].dtype.is_numeric()]
    
    if not feature_cols or target_col not in df.columns:
        print("  ‚ùå –ù–µ—Ç —Ñ–∏—á–µ–π –∏–ª–∏ —Ç–∞—Ä–≥–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        return
    
    # –û—á–∏—Å—Ç–∫–∞ –æ—Ç NaN
    df_train = df.select(feature_cols + [target_col]).drop_nulls()
    
    if len(df_train) < 100:
        print(f"  ‚ùå –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏: {len(df_train)}")
        return
    
    X = df_train.select(feature_cols).to_numpy()
    y = df_train.select(target_col).to_numpy().flatten()
    
    print(f"  –°—ç–º–ø–ª–æ–≤: {len(X):,}")
    print(f"  –§–∏—á–µ–π: {len(feature_cols)}")
    
    # –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    tracker.start_experiment(
        name=f"{platform}_{mode}_v1",
        tags=[platform, mode, "baseline"],
    )
    
    try:
        cv_result = cross_validate(
            X, y,
            model_fn="lightgbm",
            params={"num_leaves": 31, "learning_rate": 0.05, "verbose": -1},
            n_folds=mode_config["n_folds"],
            log_to_comet=True,
        )
        
        print(f"\n  ‚úì CV Mean: {cv_result['cv_mean']:.4f}")
        print(f"  ‚úì CV Std: {cv_result['cv_std']:.4f}")
        print(f"  ‚úì Fold scores: {[f'{s:.4f}' for s in cv_result['fold_scores']]}")
        
        tracker.log_metrics({
            "cv_mean": cv_result["cv_mean"],
            "cv_std": cv_result["cv_std"],
        })
        
    except Exception as e:
        print(f"  ‚ùå Training error: {e}")
        import traceback
        traceback.print_exc()
    
    # –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    experiment_result = tracker.end_experiment()
    if experiment_result:
        print(f"\n  üìä Experiment: {experiment_result.experiment_url}")
    
    # 8. –ë—é–¥–∂–µ—Ç
    print_step(8, "Budget Summary")
    budget = tracer.get_budget_status()
    print(f"  üí∞ –ü–æ—Ç—Ä–∞—á–µ–Ω–æ: ${budget.total_spent_usd:.4f}")
    print(f"  üí∞ –û—Å—Ç–∞–ª–æ—Å—å: ${budget.remaining_usd:.2f}")
    print(f"  üí∞ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {budget.percentage_used:.1f}%")
    
    print_header("‚úÖ –ó–∞–ø—É—Å–∫ –∑–∞–≤–µ—Ä—à—ë–Ω!")
    
    # –ü–æ–¥—Å–∫–∞–∑–∫–∏
    print("\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
    if mode == "debug":
        print("  ‚Üí –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print("  ‚Üí –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å --mode test –¥–ª—è –±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞")
    elif mode == "test":
        print("  ‚Üí –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Comet ML")
        print("  ‚Üí –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å --mode full –¥–ª—è –±–æ–µ–≤–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞")
    else:
        print("  ‚Üí –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Comet ML")
        print("  ‚Üí –°–¥–µ–ª–∞–π—Ç–µ —Å–∞–±–º–∏—Ç, –µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ö–æ—Ä–æ—à–∏–µ")


def main():
    parser = argparse.ArgumentParser(
        description="Comet-Swarm: –ó–∞–ø—É—Å–∫ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è—Ö",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã:
  # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ Wundernn
  uv run python examples/run_competition.py --platform wundernn --mode debug

  # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ –Ω–∞ Kaggle
  uv run python examples/run_competition.py --platform kaggle --mode test

  # –ü–æ–ª–Ω—ã–π –∑–∞–ø—É—Å–∫ —Å —Å–≤–æ–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏
  uv run python examples/run_competition.py --platform solafune --mode full --data-path ./data/train.csv

  # Dry run (—Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å –ø–ª–∞–Ω)
  uv run python examples/run_competition.py --platform wundernn --dry-run
        """,
    )
    
    parser.add_argument(
        "--platform", "-p",
        choices=list(PLATFORMS.keys()),
        required=True,
        help="–ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è",
    )
    
    parser.add_argument(
        "--mode", "-m",
        choices=list(MODES.keys()),
        default="debug",
        help="–†–µ–∂–∏–º –∑–∞–ø—É—Å–∫–∞ (default: debug)",
    )
    
    parser.add_argument(
        "--data-path", "-d",
        type=str,
        default=None,
        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–∞–Ω–Ω—ã—Ö (–≤–º–µ—Å—Ç–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è)",
    )
    
    parser.add_argument(
        "--skip-download",
        action="store_true",
        help="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–∞–Ω–µ–µ —Å–∫–∞—á–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ",
    )
    
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="–ü–æ–∫–∞–∑–∞—Ç—å –ø–ª–∞–Ω –±–µ–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è",
    )
    
    args = parser.parse_args()
    
    asyncio.run(run_competition(
        platform=args.platform,
        mode=args.mode,
        data_path=args.data_path,
        skip_download=args.skip_download,
        dry_run=args.dry_run,
    ))


if __name__ == "__main__":
    main()
